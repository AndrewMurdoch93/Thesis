\chapter{Introduction}
\label{chp:introduction}

Autonomous cars have the potential to revolutionise transportation by providing mobility to a broad range of people. 
These vehicles could (a) increase the independence of those who are incapable of driving, (b) reduce the number of road accidents caused by driver negligence, and (c) reduce both road congestion and pollution by optimising routes and driving style. 
These are just a few ways in which autonomous cars are expected to impact our daily lives \cite{klaver}. 

There are numerous challenges to the large-scale deployment of road-going autonomous cars. 
In particular, public roads are an unpredictable environment, and autonomous cars face a wide variety of scenarios that are difficult to program for.
There are many edge cases that will require the vehicle to not only respond quickly, but also operate at its handling limits to ensure the safety of its occupants.
An example of such a scenario is avoiding a collision \cite{Barab_s_2017}. 

The emergence of autonomous racing as a research field stems from the need to design autonomous driving solutions that address these edge cases.
Racing leagues such as Formula Student Driverless \cite{Hanqing2018}, Indy Autonomous Challenge \cite{Wischnewski2022} and F1tenth \cite{Babu2020} provide competitive environments for teams to develop autonomous algorithms that operate vehicles at the edge of their handling limits.
In particular, F1tenth scaled racing cars, shown in Figure \ref{fig:f1tenth_car}, is an ideal research platform due to their standardised hardware requirements and well-developed simulators.
% Furthermore, the similarity of racing and road-going scenarios allows developments in \cite{Weiss2020a}.

\begin{figure}[htb]
\centering
  \includegraphics[width=.4\textwidth]{contents/chapt1/figs/f1tenth_car.png}
  \captionof{figure}[The F1tenth standard racecar]{A standard F1tenth vehicle, built on the chassis of a miniature RC car \cite{f1tenth}.}
  \label{fig:f1tenth_car}
\end{figure}

\section{Research motivation}

Racing vehicles such as F1tenth cars are equipped with light detection and ranging (LiDAR) scanners, inertial measurement units (IMU) and rotational encoders.
Autonomous racing algorithms must convert data from these sensors into steering and throttle actuator commands  that safely move a vehicle around a track in the shortest possible time.
Therefore, these algorithms must optimise for two objectives;
(a) performance, i.e., operating the vehicle at the handling limits to achieve the fastest lap time, and (b) safety, which is to ensure that the vehicle does not collide with the track boundary or obstacles such as other cars.
These two objectives are inherently in conflict with each other because operating the vehicle close to its handling limit increases the risk of losing control \cite{Betz2021}.

A recent breakthrough in autonomous racing was the introduction of learning-based solutions, such as reinforcement learning (RL) for vehicle control.
Reinforcement learning is a machine learning paradigm where an agent learns to make sequential decisions by interacting with an environment to maximize cumulative rewards.
By setting up a reward signal that is maximised through fast and safe lap completion, RL agents can learn to race effectively.
Interestingly, RL algorithms are commonly implemented within an end-to-end architecture, whereby a deep neural network (DNN) is trained to map sensor data directly to actuator commands \cite{Betz2021}.
These end-to-end RL approaches have achieved excellent results in scenarios that are considered challenging for classical approaches that separate the planning and control tasks.
These scenarios include racing with low computational budgets \cite{Evans2021a, Tatulea-Codrean2020} and racing against multiple vehicles \cite{Song2021, Wurman2022}.

Most RL agents undergo training in simulation before their deployment on physical vehicles \cite{Babu2020, Zhou2020}.
To ensure a consistent environment between training and deployment, simulators attempt to replicate the real world as closely as possible.
This involves employing system identification techniques to create precise vehicle dynamics models \cite{Zhou2020}.
However, estimating the parameters of the vehicle model is challenging due to the dynamic nature of the driving task. 
In fact, it is inevitable that these parameters undergo changes over time \cite{Zhao2017}.
As a result, it is likely that the vehicle dynamics model employed during training does not align with the real-world vehicle dynamics. 
This phenomenon, known as model mismatch, leads to a decline in performance \cite{Ghignone2022}. 
Since some level of model mismatch is always present, accurate system identification alone is insufficient to ensure the vehicle's safety. 
It is imperative that autonomous vehicles exhibit robustness towards modeling errors.

Research efforts into addressing this challenge in RL approaches have largely been limited to modifying the DNN training process.
For example, \emph{sim-to-real} best practices include randomising vehicle model parameters during training \cite{Ivanov2020}, or retraining the DNN after deployment \cite{Zhou2020}.
Despite these efforts, the performance of learning-based methods is still negatively affected when there is model mismatch present \cite{hsu2022}.


\section{Aims and objectives}\label{sec:objectives}

The aim of this project is to develop a reinforcement learning autonomous racing algorithm that is robust to the vehicle modelling errors associated with real-world deployment.
As such, our racing algorithm must minimise lap time and drive safely under conditions where model mismatch is present.
The racing scenario that we consider is a single-vehicle time trial, whereby the vehicle must complete laps while being alone on the track.
Furthermore, our proposed solution should be compared to current RL solutions for autonomous racing.
Therefore, our objectives are stated as:
\begin{enumerate}
    \item Investigate the literature regarding methods for developing autonomous racing algorithms, with a focus on methods that are robust to vehicle modelling error.
    % \item Derive a suitable vehicle dynamics model that captures dynamics close to the edge of the handling limit.
    % \item Identify and implement an appropriate simulation that captures vehicle dynamics close to the edge of the handling limit.
    \item Identify and implement an appropriate baseline reinforcement learning autonomous racing algorithm.
    \item Design a reinforcement learning autonomous racing algorithm that is robust to vehicle modelling errors.
    \item Simulate the baseline and proposed racing algorithms under practical model mismatch conditions.
\end{enumerate}



\section{Document outline}\label{sec:outline}

Chapter \ref{chp:litreview} constitutes an overview of the existing approaches to solving the autonomous racing problem in literature.
A variety of classical and learning-based solutions are discussed, with a focus on how these methods handle uncertainty in the vehicle model.
We identify a suitable research avenue in methods that seek to unify ideas from classical and learning-based approaches by utilising a DNN within a classical (i.e., decoupled) structure.
Methods that utilise this approach are known as \emph{partial end-to-end}.

The literature study is followed with the an overview of the necessary theory to understand reinforcement learning in Chapter \ref{chp:rl}.
An essential component in training a reinforcement learning algorithm to complete a robotic task is a realistic simulator.
As such, Chapter \ref{chp:modelling} describes how the racing environment was modelled in a suitable custom F1tenth simulator.

Chapter \ref{chp:end_to_end_autonomous_racing} the baseline end-to-end RL solution, as well as the techniques for applying an RL algorithm to solve the racing problem.
This end-to-end algorithm is extensively evaluated in racing conditions where no model mismatch is present.
Furthermore, the effectiveness of \emph{sim-to-real} techniques for end-to-end methods in the context of autonomous racing is investigated.

Chapter \ref{chp:partial_end_to_end_autonomous_racing} describes our partial end-to-end solution to the autonomous racing problem.
This chapter compares the performance of our chosen partial end-to-end architecture against the end-to-end baseline algorithm, 
as well as the performance of several alternative partial end-to-end architectures against each other.

The experiments that were performed under model mismatch conditions are found in Chapter \ref{chp:racing}.
This chapter considers practical model mismatch settings that could be encountered during real-world transfer, such as adding a dynamic mass to the vehicle, 
changing tire parameters, as well as a change in the road surface friction coefficient.
The thesis is then concluded in Chapter \ref{chp:conclusion} with a summary of the work completed, as well as recommendations for future work.
